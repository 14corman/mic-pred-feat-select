{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Neural Network\n",
    "This notebook will work over creating and working with the Neural Network used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: The directory '/home/cory/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.2.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.8/dist-packages (1.19.5)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.4.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.8/dist-packages (2.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/cory/.local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/cory/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.15.8)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.32.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.6.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (45.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy~=1.19.2 sklearn matplotlib seaborn tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "source": [
    "## Load data\n",
    "Load the preprocessed training/testing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ompk35 = pd.read_csv(\"../data/processed/form_3_ompk35.csv\", index_col=0)\n",
    "ompk36 = pd.read_csv(\"../data/processed/form_3_ompk36.csv\", index_col=0)\n",
    "ompk37 = pd.read_csv(\"../data/processed/form_3_ompk37.csv\", index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"../data/processed/labels.csv\", index_col=0)\n",
    "set_mics = pd.read_csv(\"../data/processed/mic_set.csv\")"
   ]
  },
  {
   "source": [
    "## Rename columns\n",
    "We will be merging all columns together and performing an inner join on the rows. In order to do that, we need to make sure all columns for each gene have different names. Otherwise, the columns will be merged."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_columns(df, gene_name):\n",
    "    df = df.set_axis([i for i in range(len(df.columns))], axis=1)\n",
    "    df = df.add_prefix(f'{gene_name}_')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ompk35 = set_columns(ompk35, 'ompk35')\n",
    "ompk36 = set_columns(ompk36, 'ompk36')\n",
    "ompk37 = set_columns(ompk37, 'ompk37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_3 = pd.concat([ompk35, ompk36, ompk37], axis=1, join='inner')"
   ]
  },
  {
   "source": [
    "## Setting labels\n",
    "The labels contain all isolates that have no holes for at least 1 gene. However, we want to get isolates that have no holes for all genes. For that, we will need to shrink the list of labels down to only have isolates that are in form_3 variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[labels.index.isin(form_3.index)]"
   ]
  },
  {
   "source": [
    "## Sorting data and labels\n",
    "The labels and data must be in sorted order when training. Otherwise, the an MIC value could be matched up with the wrong datapoint."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.sort_index()\n",
    "form_3 = form_3.sort_index()"
   ]
  },
  {
   "source": [
    "## Update 4 from XGBoost required here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_labels(x, classes=[]):\n",
    "    \"\"\"Scaling down labels to be [0, num_classes)\"\"\"\n",
    "    return classes.index(x)  # np.where(classes == x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(labels['Antibiotic_1'].unique())\n",
    "classes.sort()\n",
    "y = labels['Antibiotic_1'].apply(scale_labels, classes=classes)"
   ]
  },
  {
   "source": [
    "# Network\n",
    "The first network that will be tried is the small, one-hidden-layer NN from the from:\n",
    "\n",
    "D. Aytan-Aktug, P. T. L. C. Clausen, V. Bortolaia, F. M. Aarestrup, and O. Lund. \"Prediction of Acquired Antimicrobial Resistance for Multiple Bacterial Species Using Neural Networks\". American Society for Microbiology Journals, January 5, 2020, e00774-19. [https://doi.org/10.1128/MSYSTEMS.00774-19](https://doi.org/10.1128/MSYSTEMS.00774-19).\n",
    "\n",
    "It has a hidden layer with 200 neurons."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = len(form_3.columns)\n",
    "num_mics = len(classes)\n",
    "model = keras.Sequential(\n",
    "                    [\n",
    "                        layers.Dense(200, activation=\"relu\", name=\"hidden\", input_shape=(num_genes,)),\n",
    "                        layers.Dense(num_mics, activation=\"softmax\", name=\"output\"),\n",
    "                    ])"
   ]
  },
  {
   "source": [
    "# Summary of model\n",
    "Let's see what the summary of the model shows to see if we have the right structure."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nhidden (Dense)               (None, 200)               230000    \n_________________________________________________________________\noutput (Dense)               (None, 7)                 1407      \n=================================================================\nTotal params: 231,407\nTrainable params: 231,407\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "# Compile model\n",
    "Next, we need to compile the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_crossentropy', 'sparse_categorical_accuracy'])"
   ]
  },
  {
   "source": [
    "# Train the model\n",
    "We want to use 20% of the input data for validation, and we want to shuffle all data (that is set to true by default). Even with large batch size and number of epochs, it has high loss for both training and validation which means it is underfitting the data. Because of this, next I will try DeepARG model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6302 - val_sparse_categorical_crossentropy: 1.6302 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.6338 - sparse_categorical_crossentropy: 1.6338 - sparse_categorical_accuracy: 0.5046 - val_loss: 1.6227 - val_sparse_categorical_crossentropy: 1.6227 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.6288 - sparse_categorical_crossentropy: 1.6288 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.6155 - val_sparse_categorical_crossentropy: 1.6155 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6250 - sparse_categorical_crossentropy: 1.6250 - sparse_categorical_accuracy: 0.4921 - val_loss: 1.6086 - val_sparse_categorical_crossentropy: 1.6086 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.6105 - sparse_categorical_crossentropy: 1.6105 - sparse_categorical_accuracy: 0.5036 - val_loss: 1.6019 - val_sparse_categorical_crossentropy: 1.6019 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5827 - sparse_categorical_crossentropy: 1.5827 - sparse_categorical_accuracy: 0.5236 - val_loss: 1.5955 - val_sparse_categorical_crossentropy: 1.5955 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.6104 - sparse_categorical_crossentropy: 1.6104 - sparse_categorical_accuracy: 0.4912 - val_loss: 1.5894 - val_sparse_categorical_crossentropy: 1.5894 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6023 - sparse_categorical_crossentropy: 1.6023 - sparse_categorical_accuracy: 0.4885 - val_loss: 1.5835 - val_sparse_categorical_crossentropy: 1.5835 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5834 - sparse_categorical_crossentropy: 1.5834 - sparse_categorical_accuracy: 0.5079 - val_loss: 1.5779 - val_sparse_categorical_crossentropy: 1.5779 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5984 - sparse_categorical_crossentropy: 1.5984 - sparse_categorical_accuracy: 0.4750 - val_loss: 1.5724 - val_sparse_categorical_crossentropy: 1.5724 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5949 - sparse_categorical_crossentropy: 1.5949 - sparse_categorical_accuracy: 0.4707 - val_loss: 1.5672 - val_sparse_categorical_crossentropy: 1.5672 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5734 - sparse_categorical_crossentropy: 1.5734 - sparse_categorical_accuracy: 0.4927 - val_loss: 1.5623 - val_sparse_categorical_crossentropy: 1.5623 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5696 - sparse_categorical_crossentropy: 1.5696 - sparse_categorical_accuracy: 0.4852 - val_loss: 1.5573 - val_sparse_categorical_crossentropy: 1.5573 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5640 - sparse_categorical_crossentropy: 1.5640 - sparse_categorical_accuracy: 0.5045 - val_loss: 1.5529 - val_sparse_categorical_crossentropy: 1.5529 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5454 - sparse_categorical_crossentropy: 1.5454 - sparse_categorical_accuracy: 0.4992 - val_loss: 1.5484 - val_sparse_categorical_crossentropy: 1.5484 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5287 - sparse_categorical_crossentropy: 1.5287 - sparse_categorical_accuracy: 0.5223 - val_loss: 1.5442 - val_sparse_categorical_crossentropy: 1.5442 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5459 - sparse_categorical_crossentropy: 1.5459 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.5401 - val_sparse_categorical_crossentropy: 1.5401 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5411 - sparse_categorical_crossentropy: 1.5411 - sparse_categorical_accuracy: 0.4958 - val_loss: 1.5362 - val_sparse_categorical_crossentropy: 1.5362 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5203 - sparse_categorical_crossentropy: 1.5203 - sparse_categorical_accuracy: 0.5108 - val_loss: 1.5325 - val_sparse_categorical_crossentropy: 1.5325 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5689 - sparse_categorical_crossentropy: 1.5689 - sparse_categorical_accuracy: 0.4660 - val_loss: 1.5288 - val_sparse_categorical_crossentropy: 1.5288 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5236 - sparse_categorical_crossentropy: 1.5236 - sparse_categorical_accuracy: 0.4965 - val_loss: 1.5253 - val_sparse_categorical_crossentropy: 1.5253 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5388 - sparse_categorical_crossentropy: 1.5388 - sparse_categorical_accuracy: 0.4864 - val_loss: 1.5220 - val_sparse_categorical_crossentropy: 1.5220 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5462 - sparse_categorical_crossentropy: 1.5462 - sparse_categorical_accuracy: 0.4749 - val_loss: 1.5188 - val_sparse_categorical_crossentropy: 1.5188 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5269 - sparse_categorical_crossentropy: 1.5269 - sparse_categorical_accuracy: 0.4910 - val_loss: 1.5158 - val_sparse_categorical_crossentropy: 1.5158 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5391 - sparse_categorical_crossentropy: 1.5391 - sparse_categorical_accuracy: 0.4807 - val_loss: 1.5129 - val_sparse_categorical_crossentropy: 1.5129 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5179 - sparse_categorical_crossentropy: 1.5179 - sparse_categorical_accuracy: 0.4885 - val_loss: 1.5101 - val_sparse_categorical_crossentropy: 1.5101 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5345 - sparse_categorical_crossentropy: 1.5345 - sparse_categorical_accuracy: 0.4762 - val_loss: 1.5076 - val_sparse_categorical_crossentropy: 1.5076 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5257 - sparse_categorical_crossentropy: 1.5257 - sparse_categorical_accuracy: 0.4786 - val_loss: 1.5049 - val_sparse_categorical_crossentropy: 1.5049 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5399 - sparse_categorical_crossentropy: 1.5399 - sparse_categorical_accuracy: 0.4747 - val_loss: 1.5023 - val_sparse_categorical_crossentropy: 1.5023 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5065 - sparse_categorical_crossentropy: 1.5065 - sparse_categorical_accuracy: 0.4939 - val_loss: 1.5002 - val_sparse_categorical_crossentropy: 1.5002 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5030 - sparse_categorical_crossentropy: 1.5030 - sparse_categorical_accuracy: 0.4973 - val_loss: 1.4976 - val_sparse_categorical_crossentropy: 1.4976 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4962 - sparse_categorical_crossentropy: 1.4962 - sparse_categorical_accuracy: 0.5018 - val_loss: 1.4955 - val_sparse_categorical_crossentropy: 1.4955 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.5145 - sparse_categorical_crossentropy: 1.5145 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.4933 - val_sparse_categorical_crossentropy: 1.4933 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4809 - sparse_categorical_crossentropy: 1.4809 - sparse_categorical_accuracy: 0.5131 - val_loss: 1.4913 - val_sparse_categorical_crossentropy: 1.4913 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4989 - sparse_categorical_crossentropy: 1.4989 - sparse_categorical_accuracy: 0.4929 - val_loss: 1.4893 - val_sparse_categorical_crossentropy: 1.4893 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5072 - sparse_categorical_crossentropy: 1.5072 - sparse_categorical_accuracy: 0.4860 - val_loss: 1.4875 - val_sparse_categorical_crossentropy: 1.4875 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4925 - sparse_categorical_crossentropy: 1.4925 - sparse_categorical_accuracy: 0.5025 - val_loss: 1.4857 - val_sparse_categorical_crossentropy: 1.4857 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4936 - sparse_categorical_crossentropy: 1.4936 - sparse_categorical_accuracy: 0.4953 - val_loss: 1.4838 - val_sparse_categorical_crossentropy: 1.4838 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4755 - sparse_categorical_crossentropy: 1.4755 - sparse_categorical_accuracy: 0.5037 - val_loss: 1.4823 - val_sparse_categorical_crossentropy: 1.4823 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4925 - sparse_categorical_crossentropy: 1.4925 - sparse_categorical_accuracy: 0.4886 - val_loss: 1.4805 - val_sparse_categorical_crossentropy: 1.4805 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5148 - sparse_categorical_crossentropy: 1.5148 - sparse_categorical_accuracy: 0.4775 - val_loss: 1.4791 - val_sparse_categorical_crossentropy: 1.4791 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4984 - sparse_categorical_crossentropy: 1.4984 - sparse_categorical_accuracy: 0.4835 - val_loss: 1.4777 - val_sparse_categorical_crossentropy: 1.4777 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4788 - sparse_categorical_crossentropy: 1.4788 - sparse_categorical_accuracy: 0.4935 - val_loss: 1.4761 - val_sparse_categorical_crossentropy: 1.4761 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4940 - sparse_categorical_crossentropy: 1.4940 - sparse_categorical_accuracy: 0.4934 - val_loss: 1.4737 - val_sparse_categorical_crossentropy: 1.4737 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4854 - sparse_categorical_crossentropy: 1.4854 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.4729 - val_sparse_categorical_crossentropy: 1.4729 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5022 - sparse_categorical_crossentropy: 1.5022 - sparse_categorical_accuracy: 0.4847 - val_loss: 1.4720 - val_sparse_categorical_crossentropy: 1.4720 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4997 - sparse_categorical_crossentropy: 1.4997 - sparse_categorical_accuracy: 0.4800 - val_loss: 1.4707 - val_sparse_categorical_crossentropy: 1.4707 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4623 - sparse_categorical_crossentropy: 1.4623 - sparse_categorical_accuracy: 0.4998 - val_loss: 1.4695 - val_sparse_categorical_crossentropy: 1.4695 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4791 - sparse_categorical_crossentropy: 1.4791 - sparse_categorical_accuracy: 0.4925 - val_loss: 1.4684 - val_sparse_categorical_crossentropy: 1.4684 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4496 - sparse_categorical_crossentropy: 1.4496 - sparse_categorical_accuracy: 0.5083 - val_loss: 1.4672 - val_sparse_categorical_crossentropy: 1.4672 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4837 - sparse_categorical_crossentropy: 1.4837 - sparse_categorical_accuracy: 0.4940 - val_loss: 1.4662 - val_sparse_categorical_crossentropy: 1.4662 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4688 - sparse_categorical_crossentropy: 1.4688 - sparse_categorical_accuracy: 0.4945 - val_loss: 1.4652 - val_sparse_categorical_crossentropy: 1.4652 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4714 - sparse_categorical_crossentropy: 1.4714 - sparse_categorical_accuracy: 0.5006 - val_loss: 1.4642 - val_sparse_categorical_crossentropy: 1.4642 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4818 - sparse_categorical_crossentropy: 1.4818 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.4634 - val_sparse_categorical_crossentropy: 1.4634 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4700 - sparse_categorical_crossentropy: 1.4700 - sparse_categorical_accuracy: 0.4887 - val_loss: 1.4623 - val_sparse_categorical_crossentropy: 1.4623 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4825 - sparse_categorical_crossentropy: 1.4825 - sparse_categorical_accuracy: 0.4797 - val_loss: 1.4611 - val_sparse_categorical_crossentropy: 1.4611 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4377 - sparse_categorical_crossentropy: 1.4377 - sparse_categorical_accuracy: 0.5171 - val_loss: 1.4603 - val_sparse_categorical_crossentropy: 1.4603 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4635 - sparse_categorical_crossentropy: 1.4635 - sparse_categorical_accuracy: 0.4939 - val_loss: 1.4597 - val_sparse_categorical_crossentropy: 1.4597 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4654 - sparse_categorical_crossentropy: 1.4654 - sparse_categorical_accuracy: 0.4955 - val_loss: 1.4586 - val_sparse_categorical_crossentropy: 1.4586 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4629 - sparse_categorical_crossentropy: 1.4629 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.4581 - val_sparse_categorical_crossentropy: 1.4581 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4469 - sparse_categorical_crossentropy: 1.4469 - sparse_categorical_accuracy: 0.4967 - val_loss: 1.4574 - val_sparse_categorical_crossentropy: 1.4574 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4819 - sparse_categorical_crossentropy: 1.4819 - sparse_categorical_accuracy: 0.4773 - val_loss: 1.4563 - val_sparse_categorical_crossentropy: 1.4563 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4259 - sparse_categorical_crossentropy: 1.4259 - sparse_categorical_accuracy: 0.5170 - val_loss: 1.4560 - val_sparse_categorical_crossentropy: 1.4560 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4736 - sparse_categorical_crossentropy: 1.4736 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.4554 - val_sparse_categorical_crossentropy: 1.4554 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4736 - sparse_categorical_crossentropy: 1.4736 - sparse_categorical_accuracy: 0.4832 - val_loss: 1.4545 - val_sparse_categorical_crossentropy: 1.4545 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4711 - sparse_categorical_crossentropy: 1.4711 - sparse_categorical_accuracy: 0.4856 - val_loss: 1.4537 - val_sparse_categorical_crossentropy: 1.4537 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4494 - sparse_categorical_crossentropy: 1.4494 - sparse_categorical_accuracy: 0.4981 - val_loss: 1.4532 - val_sparse_categorical_crossentropy: 1.4532 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4369 - sparse_categorical_crossentropy: 1.4369 - sparse_categorical_accuracy: 0.5127 - val_loss: 1.4529 - val_sparse_categorical_crossentropy: 1.4529 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4565 - sparse_categorical_crossentropy: 1.4565 - sparse_categorical_accuracy: 0.4963 - val_loss: 1.4523 - val_sparse_categorical_crossentropy: 1.4523 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4501 - sparse_categorical_crossentropy: 1.4501 - sparse_categorical_accuracy: 0.4980 - val_loss: 1.4514 - val_sparse_categorical_crossentropy: 1.4514 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4396 - sparse_categorical_crossentropy: 1.4396 - sparse_categorical_accuracy: 0.4968 - val_loss: 1.4512 - val_sparse_categorical_crossentropy: 1.4512 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4462 - sparse_categorical_crossentropy: 1.4462 - sparse_categorical_accuracy: 0.5018 - val_loss: 1.4507 - val_sparse_categorical_crossentropy: 1.4507 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.4695 - sparse_categorical_crossentropy: 1.4695 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.4498 - val_sparse_categorical_crossentropy: 1.4498 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4417 - sparse_categorical_crossentropy: 1.4417 - sparse_categorical_accuracy: 0.4990 - val_loss: 1.4494 - val_sparse_categorical_crossentropy: 1.4494 - val_sparse_categorical_accuracy: 0.5347\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4368 - sparse_categorical_crossentropy: 1.4368 - sparse_categorical_accuracy: 0.5004 - val_loss: 1.4493 - val_sparse_categorical_crossentropy: 1.4493 - val_sparse_categorical_accuracy: 0.5347\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe476b220d0>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.fit(form_3, y, batch_size=100, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "source": [
    "# Building and compiling DeepARG model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential(\n",
    "                    [\n",
    "                        layers.Dense(2000, activation=\"relu\", input_shape=(num_genes,)),\n",
    "                        layers.Dropout(0.5),\n",
    "                        layers.Dense(1000, activation=\"relu\"),\n",
    "                        layers.Dropout(0.5),\n",
    "                        layers.Dense(500, activation=\"relu\"),\n",
    "                        layers.Dropout(0.5),\n",
    "                        layers.Dense(100, activation=\"relu\"),\n",
    "                        layers.Dense(num_mics, activation=\"softmax\", name=\"output\"),\n",
    "                    ])\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_crossentropy', 'sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "al_accuracy: 0.5918\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2906 - sparse_categorical_crossentropy: 1.2906 - sparse_categorical_accuracy: 0.5718 - val_loss: 1.4077 - val_sparse_categorical_crossentropy: 1.4077 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 1.3074 - sparse_categorical_crossentropy: 1.3074 - sparse_categorical_accuracy: 0.5879 - val_loss: 1.4155 - val_sparse_categorical_crossentropy: 1.4155 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 1.3512 - sparse_categorical_crossentropy: 1.3512 - sparse_categorical_accuracy: 0.5567 - val_loss: 1.3951 - val_sparse_categorical_crossentropy: 1.3951 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 1.2916 - sparse_categorical_crossentropy: 1.2916 - sparse_categorical_accuracy: 0.5943 - val_loss: 1.3550 - val_sparse_categorical_crossentropy: 1.3550 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.3070 - sparse_categorical_crossentropy: 1.3070 - sparse_categorical_accuracy: 0.5765 - val_loss: 1.3612 - val_sparse_categorical_crossentropy: 1.3612 - val_sparse_categorical_accuracy: 0.5633\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2684 - sparse_categorical_crossentropy: 1.2684 - sparse_categorical_accuracy: 0.5868 - val_loss: 1.3963 - val_sparse_categorical_crossentropy: 1.3963 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2921 - sparse_categorical_crossentropy: 1.2921 - sparse_categorical_accuracy: 0.5803 - val_loss: 1.3651 - val_sparse_categorical_crossentropy: 1.3651 - val_sparse_categorical_accuracy: 0.5633\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.2675 - sparse_categorical_crossentropy: 1.2675 - sparse_categorical_accuracy: 0.5967 - val_loss: 1.4586 - val_sparse_categorical_crossentropy: 1.4586 - val_sparse_categorical_accuracy: 0.5510\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.3083 - sparse_categorical_crossentropy: 1.3083 - sparse_categorical_accuracy: 0.5620 - val_loss: 1.4228 - val_sparse_categorical_crossentropy: 1.4228 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3357 - sparse_categorical_crossentropy: 1.3357 - sparse_categorical_accuracy: 0.5628 - val_loss: 1.3696 - val_sparse_categorical_crossentropy: 1.3696 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2882 - sparse_categorical_crossentropy: 1.2882 - sparse_categorical_accuracy: 0.5701 - val_loss: 1.3657 - val_sparse_categorical_crossentropy: 1.3657 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2796 - sparse_categorical_crossentropy: 1.2796 - sparse_categorical_accuracy: 0.5809 - val_loss: 1.3791 - val_sparse_categorical_crossentropy: 1.3791 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 1.3083 - sparse_categorical_crossentropy: 1.3083 - sparse_categorical_accuracy: 0.5682 - val_loss: 1.3540 - val_sparse_categorical_crossentropy: 1.3540 - val_sparse_categorical_accuracy: 0.5633\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3162 - sparse_categorical_crossentropy: 1.3162 - sparse_categorical_accuracy: 0.5683 - val_loss: 1.3874 - val_sparse_categorical_crossentropy: 1.3874 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2947 - sparse_categorical_crossentropy: 1.2947 - sparse_categorical_accuracy: 0.5844 - val_loss: 1.3743 - val_sparse_categorical_crossentropy: 1.3743 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2675 - sparse_categorical_crossentropy: 1.2675 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.3785 - val_sparse_categorical_crossentropy: 1.3785 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.2904 - sparse_categorical_crossentropy: 1.2904 - sparse_categorical_accuracy: 0.5826 - val_loss: 1.3630 - val_sparse_categorical_crossentropy: 1.3630 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.3207 - sparse_categorical_crossentropy: 1.3207 - sparse_categorical_accuracy: 0.5584 - val_loss: 1.3896 - val_sparse_categorical_crossentropy: 1.3896 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3000 - sparse_categorical_crossentropy: 1.3000 - sparse_categorical_accuracy: 0.5829 - val_loss: 1.3469 - val_sparse_categorical_crossentropy: 1.3469 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 1.3268 - sparse_categorical_crossentropy: 1.3268 - sparse_categorical_accuracy: 0.5574 - val_loss: 1.3486 - val_sparse_categorical_crossentropy: 1.3486 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.3125 - sparse_categorical_crossentropy: 1.3125 - sparse_categorical_accuracy: 0.5739 - val_loss: 1.3759 - val_sparse_categorical_crossentropy: 1.3759 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3115 - sparse_categorical_crossentropy: 1.3115 - sparse_categorical_accuracy: 0.5845 - val_loss: 1.3829 - val_sparse_categorical_crossentropy: 1.3829 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3288 - sparse_categorical_crossentropy: 1.3288 - sparse_categorical_accuracy: 0.5661 - val_loss: 1.3456 - val_sparse_categorical_crossentropy: 1.3456 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2921 - sparse_categorical_crossentropy: 1.2921 - sparse_categorical_accuracy: 0.5647 - val_loss: 1.3962 - val_sparse_categorical_crossentropy: 1.3962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.3034 - sparse_categorical_crossentropy: 1.3034 - sparse_categorical_accuracy: 0.5758 - val_loss: 1.3551 - val_sparse_categorical_crossentropy: 1.3551 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.3315 - sparse_categorical_crossentropy: 1.3315 - sparse_categorical_accuracy: 0.5596 - val_loss: 1.3336 - val_sparse_categorical_crossentropy: 1.3336 - val_sparse_categorical_accuracy: 0.5633\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.4224 - sparse_categorical_crossentropy: 1.4224 - sparse_categorical_accuracy: 0.5548 - val_loss: 1.3536 - val_sparse_categorical_crossentropy: 1.3536 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 1.3024 - sparse_categorical_crossentropy: 1.3024 - sparse_categorical_accuracy: 0.5732 - val_loss: 1.4140 - val_sparse_categorical_crossentropy: 1.4140 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3353 - sparse_categorical_crossentropy: 1.3353 - sparse_categorical_accuracy: 0.5630 - val_loss: 1.4227 - val_sparse_categorical_crossentropy: 1.4227 - val_sparse_categorical_accuracy: 0.6041\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 51ms/step - loss: 1.2808 - sparse_categorical_crossentropy: 1.2808 - sparse_categorical_accuracy: 0.5849 - val_loss: 1.3787 - val_sparse_categorical_crossentropy: 1.3787 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2606 - sparse_categorical_crossentropy: 1.2606 - sparse_categorical_accuracy: 0.5862 - val_loss: 1.3890 - val_sparse_categorical_crossentropy: 1.3890 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 1.3068 - sparse_categorical_crossentropy: 1.3068 - sparse_categorical_accuracy: 0.5801 - val_loss: 1.3863 - val_sparse_categorical_crossentropy: 1.3863 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 1.3182 - sparse_categorical_crossentropy: 1.3182 - sparse_categorical_accuracy: 0.5716 - val_loss: 1.3739 - val_sparse_categorical_crossentropy: 1.3739 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 1.2858 - sparse_categorical_crossentropy: 1.2858 - sparse_categorical_accuracy: 0.5795 - val_loss: 1.3777 - val_sparse_categorical_crossentropy: 1.3777 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 1.2810 - sparse_categorical_crossentropy: 1.2810 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.3435 - val_sparse_categorical_crossentropy: 1.3435 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.2780 - sparse_categorical_crossentropy: 1.2780 - sparse_categorical_accuracy: 0.5726 - val_loss: 1.3903 - val_sparse_categorical_crossentropy: 1.3903 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.3152 - sparse_categorical_crossentropy: 1.3152 - sparse_categorical_accuracy: 0.5656 - val_loss: 1.3730 - val_sparse_categorical_crossentropy: 1.3730 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2788 - sparse_categorical_crossentropy: 1.2788 - sparse_categorical_accuracy: 0.5784 - val_loss: 1.3802 - val_sparse_categorical_crossentropy: 1.3802 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.2550 - sparse_categorical_crossentropy: 1.2550 - sparse_categorical_accuracy: 0.5980 - val_loss: 1.3935 - val_sparse_categorical_crossentropy: 1.3935 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 1.3016 - sparse_categorical_crossentropy: 1.3016 - sparse_categorical_accuracy: 0.5719 - val_loss: 1.3945 - val_sparse_categorical_crossentropy: 1.3945 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 1.2809 - sparse_categorical_crossentropy: 1.2809 - sparse_categorical_accuracy: 0.5797 - val_loss: 1.4217 - val_sparse_categorical_crossentropy: 1.4217 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 1.2647 - sparse_categorical_crossentropy: 1.2647 - sparse_categorical_accuracy: 0.5901 - val_loss: 1.4077 - val_sparse_categorical_crossentropy: 1.4077 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 1.3164 - sparse_categorical_crossentropy: 1.3164 - sparse_categorical_accuracy: 0.5566 - val_loss: 1.3594 - val_sparse_categorical_crossentropy: 1.3594 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 1.2398 - sparse_categorical_crossentropy: 1.2398 - sparse_categorical_accuracy: 0.6074 - val_loss: 1.3959 - val_sparse_categorical_crossentropy: 1.3959 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 1.3000 - sparse_categorical_crossentropy: 1.3000 - sparse_categorical_accuracy: 0.5644 - val_loss: 1.3809 - val_sparse_categorical_crossentropy: 1.3809 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 1.3123 - sparse_categorical_crossentropy: 1.3123 - sparse_categorical_accuracy: 0.5823 - val_loss: 1.3599 - val_sparse_categorical_crossentropy: 1.3599 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.2760 - sparse_categorical_crossentropy: 1.2760 - sparse_categorical_accuracy: 0.5831 - val_loss: 1.4140 - val_sparse_categorical_crossentropy: 1.4140 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2659 - sparse_categorical_crossentropy: 1.2659 - sparse_categorical_accuracy: 0.6034 - val_loss: 1.4038 - val_sparse_categorical_crossentropy: 1.4038 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 1.3008 - sparse_categorical_crossentropy: 1.3008 - sparse_categorical_accuracy: 0.5872 - val_loss: 1.3714 - val_sparse_categorical_crossentropy: 1.3714 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 1.2782 - sparse_categorical_crossentropy: 1.2782 - sparse_categorical_accuracy: 0.5822 - val_loss: 1.3521 - val_sparse_categorical_crossentropy: 1.3521 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 1.3303 - sparse_categorical_crossentropy: 1.3303 - sparse_categorical_accuracy: 0.5750 - val_loss: 1.3784 - val_sparse_categorical_crossentropy: 1.3784 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2683 - sparse_categorical_crossentropy: 1.2683 - sparse_categorical_accuracy: 0.5858 - val_loss: 1.4132 - val_sparse_categorical_crossentropy: 1.4132 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.3019 - sparse_categorical_crossentropy: 1.3019 - sparse_categorical_accuracy: 0.5769 - val_loss: 1.3586 - val_sparse_categorical_crossentropy: 1.3586 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.2986 - sparse_categorical_crossentropy: 1.2986 - sparse_categorical_accuracy: 0.5881 - val_loss: 1.3506 - val_sparse_categorical_crossentropy: 1.3506 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.2815 - sparse_categorical_crossentropy: 1.2815 - sparse_categorical_accuracy: 0.5772 - val_loss: 1.3919 - val_sparse_categorical_crossentropy: 1.3919 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.3371 - sparse_categorical_crossentropy: 1.3371 - sparse_categorical_accuracy: 0.5669 - val_loss: 1.3612 - val_sparse_categorical_crossentropy: 1.3612 - val_sparse_categorical_accuracy: 0.5551\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.3258 - sparse_categorical_crossentropy: 1.3258 - sparse_categorical_accuracy: 0.5687 - val_loss: 1.3790 - val_sparse_categorical_crossentropy: 1.3790 - val_sparse_categorical_accuracy: 0.5755\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2901 - sparse_categorical_crossentropy: 1.2901 - sparse_categorical_accuracy: 0.5824 - val_loss: 1.3377 - val_sparse_categorical_crossentropy: 1.3377 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2761 - sparse_categorical_crossentropy: 1.2761 - sparse_categorical_accuracy: 0.5722 - val_loss: 1.3674 - val_sparse_categorical_crossentropy: 1.3674 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.2595 - sparse_categorical_crossentropy: 1.2595 - sparse_categorical_accuracy: 0.5886 - val_loss: 1.4168 - val_sparse_categorical_crossentropy: 1.4168 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2545 - sparse_categorical_crossentropy: 1.2545 - sparse_categorical_accuracy: 0.5970 - val_loss: 1.3686 - val_sparse_categorical_crossentropy: 1.3686 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2840 - sparse_categorical_crossentropy: 1.2840 - sparse_categorical_accuracy: 0.5880 - val_loss: 1.3650 - val_sparse_categorical_crossentropy: 1.3650 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 1.2614 - sparse_categorical_crossentropy: 1.2614 - sparse_categorical_accuracy: 0.5922 - val_loss: 1.3890 - val_sparse_categorical_crossentropy: 1.3890 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.3351 - sparse_categorical_crossentropy: 1.3351 - sparse_categorical_accuracy: 0.5585 - val_loss: 1.3480 - val_sparse_categorical_crossentropy: 1.3480 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.3180 - sparse_categorical_crossentropy: 1.3180 - sparse_categorical_accuracy: 0.5754 - val_loss: 1.3637 - val_sparse_categorical_crossentropy: 1.3637 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.3536 - sparse_categorical_crossentropy: 1.3536 - sparse_categorical_accuracy: 0.5529 - val_loss: 1.3566 - val_sparse_categorical_crossentropy: 1.3566 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2539 - sparse_categorical_crossentropy: 1.2539 - sparse_categorical_accuracy: 0.5919 - val_loss: 1.3497 - val_sparse_categorical_crossentropy: 1.3497 - val_sparse_categorical_accuracy: 0.5755\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 1.3495 - sparse_categorical_crossentropy: 1.3495 - sparse_categorical_accuracy: 0.5648 - val_loss: 1.3627 - val_sparse_categorical_crossentropy: 1.3627 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.2763 - sparse_categorical_crossentropy: 1.2763 - sparse_categorical_accuracy: 0.5805 - val_loss: 1.3962 - val_sparse_categorical_crossentropy: 1.3962 - val_sparse_categorical_accuracy: 0.5959\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2701 - sparse_categorical_crossentropy: 1.2701 - sparse_categorical_accuracy: 0.6031 - val_loss: 1.3905 - val_sparse_categorical_crossentropy: 1.3905 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.2495 - sparse_categorical_crossentropy: 1.2495 - sparse_categorical_accuracy: 0.5991 - val_loss: 1.3720 - val_sparse_categorical_crossentropy: 1.3720 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1.3271 - sparse_categorical_crossentropy: 1.3271 - sparse_categorical_accuracy: 0.5666 - val_loss: 1.3532 - val_sparse_categorical_crossentropy: 1.3532 - val_sparse_categorical_accuracy: 0.5878\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 1.2859 - sparse_categorical_crossentropy: 1.2859 - sparse_categorical_accuracy: 0.5756 - val_loss: 1.4043 - val_sparse_categorical_crossentropy: 1.4043 - val_sparse_categorical_accuracy: 0.6122\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1.2743 - sparse_categorical_crossentropy: 1.2743 - sparse_categorical_accuracy: 0.5832 - val_loss: 1.4045 - val_sparse_categorical_crossentropy: 1.4045 - val_sparse_categorical_accuracy: 0.6000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe474285d60>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(form_3, y, batch_size=100, epochs=300, validation_split=0.2)"
   ]
  },
  {
   "source": [
    "# Cross Validation\n",
    "We still need to do Cross Validation to get a really good sense of how the model would perform, so that is what will be next. Code block below was mostly taken from [this StackOverflow answer](https://stackoverflow.com/a/57775402)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'buildModel' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1fd84078f314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRepeatedKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuildModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRepeatedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mform_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1_micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'buildModel' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "est = KerasClassifier(build_fn=build_model, epochs=100, batch_size=100)\n",
    "kfold= RepeatedKFold(n_splits=5, n_repeats=100)\n",
    "cv_results = cross_val_score(est, form_3, y, cv=kfold, scoring=\"f1_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.34739387, 0.14793424, 0.0982163 , ..., 0.06934967, 0.07976612,\n",
       "        0.17324272],\n",
       "       [0.41908008, 0.1555149 , 0.08490692, ..., 0.04756605, 0.06280009,\n",
       "        0.16183753],\n",
       "       [0.18169662, 0.02881275, 0.0230271 , ..., 0.04126183, 0.08896692,\n",
       "        0.63037777],\n",
       "       ...,\n",
       "       [0.38174483, 0.15214421, 0.09193739, ..., 0.05807449, 0.07138063,\n",
       "        0.16833109],\n",
       "       [0.41895375, 0.15550558, 0.08493099, ..., 0.04759885, 0.06282821,\n",
       "        0.16186136],\n",
       "       [0.41895375, 0.15550557, 0.08493099, ..., 0.04759885, 0.06282821,\n",
       "        0.16186136]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.predict(form_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}